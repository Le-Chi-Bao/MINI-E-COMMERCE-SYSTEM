# web/gradio_app.py
import gradio as gr
import pandas as pd
import plotly.graph_objects as go
from typing import Dict, List
import joblib
from feast import FeatureStore

print("üöÄ Loading Phone Prediction Models...")

class MultiModelPredictor:
    def __init__(self):
        try:
            # Load Feast store
            self.fs = FeatureStore(repo_path="../my_phone_features")
            
            # Load c·∫£ 3 models
            self.model_recom = joblib.load("../models/model_recommender.pkl")
            self.scaler_recom = joblib.load("../models/scaler_recommender.pkl")
            
            self.model_value = joblib.load("../models/model_value.pkl")
            self.scaler_value = joblib.load("../models/scaler_value.pkl")
            
            self.model_camera = joblib.load("../models/model_camera.pkl")
            self.scaler_camera = joblib.load("../models/scaler_camera.pkl")
            
            # Feature refs cho t·ª´ng model
            self.feature_refs_recom = [
                "phone_display:ScreenSize", "phone_display:PPI", "phone_display:total_resolution",
                "phone_camera:camera_score", "phone_camera:has_telephoto", "phone_camera:has_ultrawide",
                "phone_ratings:popularity_score",
                "phone_value:value_score", "phone_value:price_segment",
                "phone_product:has_warranty", "phone_product:NumberOfReview"
            ]
            
            self.feature_refs_value = [
                "phone_value:value_score", "phone_value:price_segment", 
                "phone_ratings:overall_score", "phone_ratings:display_score",
                "phone_ratings:camera_rating", "phone_display:PPI", "phone_display:ScreenSize",
                "phone_camera:camera_score", "phone_camera:main_camera_mp",
                "phone_product:NumberOfReview"
            ]
            
            self.feature_refs_camera = [
                "phone_camera:main_camera_mp", "phone_camera:num_cameras", 
                "phone_camera:has_telephoto", "phone_camera:has_ultrawide", 
                "phone_camera:has_ois", "phone_camera:camera_feature_count",
                "phone_display:PPI", "phone_display:total_resolution", "phone_display:ScreenSize",
                "phone_value:value_score", "phone_value:is_premium", 
                "phone_product:NumberOfReview"
            ]
            
            # Feature mapping
            self.features_recom = [
                'ScreenSize', 'PPI', 'total_resolution', 'camera_score', 
                'has_telephoto', 'has_ultrawide', 'popularity_score', 
                'value_score', 'price_segment', 'has_warranty', 'NumberOfReview'
            ]
            
            self.features_value = [
                'value_score', 'price_segment', 'overall_score', 'display_score', 
                'camera_rating', 'PPI', 'ScreenSize', 'camera_score', 
                'main_camera_mp', 'NumberOfReview'
            ]
            
            self.features_camera = [
                'main_camera_mp', 'num_cameras', 'has_telephoto', 'has_ultrawide', 
                'has_ois', 'camera_feature_count', 'PPI', 'total_resolution', 
                'ScreenSize', 'value_score', 'is_premium', 'NumberOfReview'
            ]
            
            print("‚úÖ All models loaded successfully!")
            
        except Exception as e:
            print(f"‚ùå Error loading models: {e}")
            raise
    
    def predict_from_features(self, services: List[str], manual_features: Dict):
        """D·ª± ƒëo√°n t·ª´ manual features"""
        try:
            results = {}
            
            # Model 1: Smart Recommender
            if "recommender" in services:
                X_recom = pd.DataFrame([manual_features])[self.features_recom]
                X_recom_scaled = self.scaler_recom.transform(X_recom)
                results['overall_score'] = round(self.model_recom.predict(X_recom_scaled)[0], 1)
            
            # Model 2: Value Detector
            if "value_detector" in services:
                X_value = pd.DataFrame([manual_features])[self.features_value]
                X_value_scaled = self.scaler_value.transform(X_value)
                results['is_premium'] = int(self.model_value.predict(X_value_scaled)[0])
                results['premium_probability'] = round(self.model_value.predict_proba(X_value_scaled)[0][1], 3)
            
            # Model 3: Camera Predictor
            if "camera_predictor" in services:
                X_camera = pd.DataFrame([manual_features])[self.features_camera]
                X_camera_scaled = self.scaler_camera.transform(X_camera)
                results['camera_rating'] = round(self.model_camera.predict(X_camera_scaled)[0], 1)
            
            return {
                'predictions': results,
                'status': 'success',
                'services_used': services
            }
            
        except Exception as e:
            return {
                'error': f"Prediction error: {str(e)}",
                'status': 'error'
            }

# ==================== VISUALIZATION ====================

def create_visualizations(predictions):
    """T·∫°o bi·ªÉu ƒë·ªì tr·ª±c quan cho 3 features ch√≠nh"""
    viz_figures = []
    
    # 1. Overall Score Gauge Chart
    if 'overall_score' in predictions:
        score = predictions['overall_score']
        overall_fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=score,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "ƒêI·ªÇM T·ªîNG QUAN", 'font': {'size': 16}},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 40], 'color': "lightcoral"},
                    {'range': [40, 70], 'color': "lightyellow"},
                    {'range': [70, 100], 'color': "lightgreen"}
                ]
            }
        ))
        overall_fig.update_layout(height=300, margin=dict(t=50, b=10))
        viz_figures.append(overall_fig)
    
    # 2. Flagship Probability Gauge
    if 'premium_probability' in predictions:
        prob = predictions['premium_probability'] * 100
        flagship_fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=prob,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "X√ÅC SU·∫§T FLAGSHIP", 'font': {'size': 16}},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "green" if prob > 50 else "red"},
            }
        ))
        flagship_fig.update_layout(height=300, margin=dict(t=50, b=10))
        viz_figures.append(flagship_fig)
    
    # 3. Camera Rating
    if 'camera_rating' in predictions:
        rating = predictions['camera_rating']
        camera_fig = go.Figure(go.Indicator(
            mode="number+delta",
            value=rating,
            number={'suffix': "/5", 'font': {'size': 40}},
            title={'text': "ƒê√ÅNH GI√Å CAMERA", 'font': {'size': 16}},
            delta={'reference': 3}
        ))
        camera_fig.update_layout(height=300, margin=dict(t=50, b=10))
        viz_figures.append(camera_fig)
    
    return viz_figures

def create_gradio_interface():
    # Kh·ªüi t·∫°o predictor
    try:
        predictor = MultiModelPredictor()
        print("‚úÖ Predictor initialized successfully!")
    except Exception as e:
        print(f"‚ùå Failed to initialize predictor: {e}")
        # Fallback: t·∫°o predictor r·ªóng
        predictor = None
    
    with gr.Blocks(
        title="H·ªá Th·ªëng D·ª± ƒêo√°n ƒêi·ªán Tho·∫°i",
        theme=gr.themes.Soft()
    ) as demo:
        
        gr.Markdown("# üì± H·ªá Th·ªëng D·ª± ƒêo√°n ƒêi·ªán Tho·∫°i")
        gr.Markdown("Nh·∫≠p th√¥ng s·ªë ƒëi·ªán tho·∫°i ƒë·ªÉ xem k·∫øt qu·∫£ d·ª± ƒëo√°n v·ªõi bi·ªÉu ƒë·ªì tr·ª±c quan")
        
        with gr.Row():
            # C·ªôt tr√°i: Input - Nh·∫≠p li·ªáu chuy√™n s√¢u
            with gr.Column(scale=1):
                gr.Markdown("### ‚å®Ô∏è Nh·∫≠p Th√¥ng S·ªë")
                
                # Service selection
                services = gr.CheckboxGroup(
                    choices=[
                        ("ƒê·ªÅ xu·∫•t t·ªïng quan", "recommender"),
                        ("Ph√°t hi·ªán flagship", "value_detector"), 
                        ("ƒê√°nh gi√° camera", "camera_predictor")
                    ],
                    label="D·ªãch v·ª• d·ª± ƒëo√°n",
                    value=["recommender", "value_detector", "camera_predictor"]
                )
                
                # Expert inputs v·ªõi accordion
                with gr.Accordion("üì± Th√¥ng s·ªë m√†n h√¨nh", open=True):
                    with gr.Row():
                        screen_size = gr.Number(label="K√≠ch th∆∞·ªõc m√†n h√¨nh (inch)", value=6.1)
                        ppi = gr.Number(label="M·∫≠t ƒë·ªô ƒëi·ªÉm ·∫£nh (PPI)", value=460)
                    total_resolution = gr.Number(label="ƒê·ªô ph√¢n gi·∫£i t·ªïng", value=2430000)
                
                with gr.Accordion("üì∏ Th√¥ng s·ªë camera", open=True):
                    with gr.Row():
                        camera_score = gr.Number(label="ƒêi·ªÉm camera", value=65.0)
                        main_camera_mp = gr.Number(label="Camera ch√≠nh (MP)", value=48.0)
                    with gr.Row():
                        num_cameras = gr.Number(label="S·ªë l∆∞·ª£ng camera", value=3)
                        camera_feature_count = gr.Number(label="S·ªë t√≠nh nƒÉng camera", value=2)
                    with gr.Row():
                        has_telephoto = gr.Checkbox(label="C√≥ telephoto", value=True)
                        has_ultrawide = gr.Checkbox(label="C√≥ ultrawide", value=True)
                        has_ois = gr.Checkbox(label="C√≥ OIS", value=True)
                
                with gr.Accordion("‚≠ê ƒêi·ªÉm ƒë√°nh gi√°", open=False):
                    with gr.Row():
                        popularity_score = gr.Number(label="ƒêi·ªÉm ph·ªï bi·∫øn", value=60.0)
                        overall_score_input = gr.Number(label="ƒêi·ªÉm t·ªïng quan", value=55.0)
                    with gr.Row():
                        display_score = gr.Number(label="ƒêi·ªÉm m√†n h√¨nh", value=70.0)
                        camera_rating_input = gr.Number(label="ƒê√°nh gi√° camera", value=3.5)
                
                with gr.Accordion("üí∞ Th√¥ng s·ªë gi√° tr·ªã", open=False):
                    with gr.Row():
                        value_score = gr.Number(label="ƒêi·ªÉm gi√° tr·ªã", value=6.5)
                        price_segment = gr.Radio(
                            choices=[("Ph·ªï th√¥ng", 0), ("T·∫ßm trung", 1), ("Cao c·∫•p", 2)], 
                            label="Ph√¢n kh√∫c gi√°",
                            value=1
                        )
                    is_premium_input = gr.Checkbox(label="L√† flagship", value=False)
                
                with gr.Accordion("üì¶ Th√¥ng s·ªë s·∫£n ph·∫©m", open=False):
                    with gr.Row():
                        has_warranty = gr.Checkbox(label="C√≥ b·∫£o h√†nh", value=True)
                        number_of_review = gr.Number(label="S·ªë ƒë√°nh gi√°", value=120)
                
                predict_btn = gr.Button("üéØ Th·ª±c Hi·ªán D·ª± ƒêo√°n", variant="primary", size="lg")
            
            # C·ªôt ph·∫£i: K·∫øt qu·∫£ + Bi·ªÉu ƒë·ªì
            with gr.Column(scale=2):
                gr.Markdown("### üìä K·∫øt Qu·∫£ D·ª± ƒêo√°n")
                
                # K·∫øt qu·∫£ d·∫°ng text
                with gr.Group():
                    gr.Markdown("#### Chi ti·∫øt k·∫øt qu·∫£")
                    overall_score_output = gr.Textbox(label="ƒêi·ªÉm t·ªïng quan", interactive=False)
                    flagship_output = gr.Textbox(label="Ph√¢n lo·∫°i flagship", interactive=False)
                    camera_output = gr.Textbox(label="ƒê√°nh gi√° camera", interactive=False)
                    status_output = gr.Textbox(label="Tr·∫°ng th√°i", value="S·∫µn s√†ng", interactive=False)
                
                # Bi·ªÉu ƒë·ªì tr·ª±c quan
                gr.Markdown("#### Bi·ªÉu ƒë·ªì tr·ª±c quan")
                with gr.Row():
                    overall_viz = gr.Plot(label="ƒêi·ªÉm t·ªïng quan")
                    flagship_viz = gr.Plot(label="X√°c su·∫•t flagship")
                with gr.Row():
                    camera_viz = gr.Plot(label="ƒê√°nh gi√° camera")
        
        # H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
        gr.Markdown("---")
        gr.Markdown("### üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng")
        gr.Markdown("1. Ch·ªçn d·ªãch v·ª• d·ª± ƒëo√°n c·∫ßn s·ª≠ d·ª•ng")
        gr.Markdown("2. Nh·∫≠p c√°c th√¥ng s·ªë ƒëi·ªán tho·∫°i trong c√°c m·ª•c t∆∞∆°ng ·ª©ng")  
        gr.Markdown("3. Nh·∫•n 'Th·ª±c Hi·ªán D·ª± ƒêo√°n' ƒë·ªÉ xem k·∫øt qu·∫£ v√† bi·ªÉu ƒë·ªì")
        gr.Markdown("4. K·∫øt qu·∫£ ƒë∆∞·ª£c d·ª± ƒëo√°n b·∫±ng Machine Learning models ƒë√£ train")

        # ==================== EVENT HANDLERS ====================

        def handle_expert_prediction(services, screen_size, ppi, total_resolution,
                                   camera_score, main_camera_mp, num_cameras, camera_feature_count,
                                   has_telephoto, has_ultrawide, has_ois, popularity_score,
                                   overall_score_input, display_score, camera_rating_input,
                                   value_score, price_segment, is_premium_input,
                                   has_warranty, number_of_review):
            """X·ª≠ l√Ω d·ª± ƒëo√°n t·ª´ manual input chuy√™n s√¢u"""
            
            if not services:
                return {
                    overall_score_output: "",
                    flagship_output: "", 
                    camera_output: "",
                    status_output: "‚ùå Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt d·ªãch v·ª•",
                    overall_viz: None,
                    flagship_viz: None,
                    camera_viz: None
                }
            
            if predictor is None:
                return {
                    overall_score_output: "",
                    flagship_output: "",
                    camera_output: "",
                    status_output: "‚ùå L·ªói: Models ch∆∞a ƒë∆∞·ª£c load",
                    overall_viz: None,
                    flagship_viz: None,
                    camera_viz: None
                }
            
            # Chu·∫©n b·ªã manual features
            manual_features = {
                "ScreenSize": screen_size,
                "PPI": ppi,
                "total_resolution": total_resolution,
                "camera_score": camera_score,
                "main_camera_mp": main_camera_mp,
                "num_cameras": num_cameras,
                "camera_feature_count": camera_feature_count,
                "has_telephoto": 1 if has_telephoto else 0,
                "has_ultrawide": 1 if has_ultrawide else 0,
                "has_ois": 1 if has_ois else 0,
                "popularity_score": popularity_score,
                "overall_score": overall_score_input,
                "display_score": display_score,
                "camera_rating": camera_rating_input,
                "value_score": value_score,
                "price_segment": price_segment,
                "is_premium": 1 if is_premium_input else 0,
                "has_warranty": 1 if has_warranty else 0,
                "NumberOfReview": number_of_review
            }
            
            try:
                # G·ªçi predictor
                result = predictor.predict_from_features(services, manual_features)
                
                if result['status'] == 'success':
                    predictions = result['predictions']
                    
                    # Format text outputs
                    overall_text = f"{predictions.get('overall_score', 'N/A')}/100" if 'overall_score' in predictions else "Ch∆∞a ch·ªçn d·ªãch v·ª•"
                    
                    if 'is_premium' in predictions:
                        flagship_status = "üì± Flagship Phone" if predictions['is_premium'] else "üì± Phone th√¥ng th∆∞·ªùng"
                        prob = predictions.get('premium_probability', 0) * 100
                        flagship_text = f"{flagship_status} (X√°c su·∫•t: {prob:.1f}%)"
                    else:
                        flagship_text = "Ch∆∞a ch·ªçn d·ªãch v·ª•"
                        
                    camera_text = f"{predictions.get('camera_rating', 'N/A')}/5.0 ‚≠ê" if 'camera_rating' in predictions else "Ch∆∞a ch·ªçn d·ªãch v·ª•"
                    
                    # Create visualizations
                    viz_figures = create_visualizations(predictions)
                    
                    return {
                        overall_score_output: overall_text,
                        flagship_output: flagship_text,
                        camera_output: camera_text,
                        status_output: "‚úÖ D·ª± ƒëo√°n th√†nh c√¥ng!",
                        overall_viz: viz_figures[0] if len(viz_figures) > 0 else None,
                        flagship_viz: viz_figures[1] if len(viz_figures) > 1 else None,
                        camera_viz: viz_figures[2] if len(viz_figures) > 2 else None
                    }
                else:
                    return {
                        overall_score_output: "",
                        flagship_output: "",
                        camera_output: "",
                        status_output: f"‚ùå {result.get('error', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}",
                        overall_viz: None,
                        flagship_viz: None,
                        camera_viz: None
                    }
                
            except Exception as e:
                return {
                    overall_score_output: "",
                    flagship_output: "",
                    camera_output: "",
                    status_output: f"‚ùå L·ªói d·ª± ƒëo√°n: {str(e)}",
                    overall_viz: None,
                    flagship_viz: None,
                    camera_viz: None
                }

        # Bind events
        predict_btn.click(
            handle_expert_prediction,
            inputs=[services, screen_size, ppi, total_resolution,
                   camera_score, main_camera_mp, num_cameras, camera_feature_count,
                   has_telephoto, has_ultrawide, has_ois, popularity_score,
                   overall_score_input, display_score, camera_rating_input,
                   value_score, price_segment, is_premium_input,
                   has_warranty, number_of_review],
            outputs=[overall_score_output, flagship_output, camera_output, status_output,
                    overall_viz, flagship_viz, camera_viz]
        )

    return demo

if __name__ == "__main__":
    demo = create_gradio_interface()
    print("‚úÖ Gradio interface created successfully!")
    print("ü§ñ Using trained ML models for prediction")
    print("üìä Features: Manual input + Visualization charts") 
    print("üåê Starting server on http://localhost:7869")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7855,
        share=False
    )